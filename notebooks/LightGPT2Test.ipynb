{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a9a9d95-d177-4414-9097-4faf97666a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e04d3cbc-9a03-4764-81de-eb2e482745d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + '/trinity/home/d.cherniuk/libs/graphviz-2.50.0/bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee9efd87-b338-4779-9e32-f0c26f8a0ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Config, GPT2Tokenizer, GPT2LMHeadModel, GPT2Model\n",
    "import torch\n",
    "from torch import nn\n",
    "import copy\n",
    "import time\n",
    "import tqdm\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from light_attention.attention import LightGPT2LMHeadModel, LightGPT2Model\n",
    "from light_attention.profile import estimate_layer_memory, mem_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3803db79-bbf3-4c85-9cc6-31302f971f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 15835"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53d4e32-683a-4724-8b54-30cdf8b11717",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b147fbcc-ff78-418e-b591-d82528aa740f",
   "metadata": {},
   "source": [
    "## Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7219ec92-4e2d-4f28-b916-22d276b5e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "configuration = GPT2Config()\n",
    "model = GPT2Model(configuration)\n",
    "# model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51604bf9-bcfd-4f62-8686-75b74a2c821f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before placing the model on GPU\n",
      "MA 0.0312 MB         Max_MA 0.0312 MB         CA 2.0 MB         Max_CA 2.0 MB \n",
      "\n",
      "After placing the model on GPU:\n",
      "MA 487.5 MB         Max_MA 487.5 MB         CA 542.0 MB         Max_CA 542.0 MB \n",
      "\n",
      "Params (empirical) 487.4688 MB\n",
      "\n",
      "Params (analytical, torch) 474.7002 MB\n",
      "\n",
      "After input batch generation, before forward pass:\n",
      "MA 487.5 MB         Max_MA 487.5 MB         CA 542.0 MB         Max_CA 542.0 MB \n",
      "\n",
      "After backward:\n",
      "MA 12119.2896 MB         Max_MA 12119.2896 MB         CA 12654.0 MB         Max_CA 12654.0 MB \n",
      "\n",
      "\n",
      "Activations (analytical, torchviz) 12195.8207 MB\n",
      "Activations (empirical) 11631.7896 MB\n"
     ]
    }
   ],
   "source": [
    "b = 4\n",
    "seq = configuration.n_positions\n",
    "# emb = configuration.n_embd\n",
    "x = torch.randint(0, configuration.vocab_size, size=(b,seq), device='cuda')\n",
    "estimate_layer_memory(copy.deepcopy(model), x, device='cuda', input_shape=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb9686f-dfeb-4aac-8ffe-6809b9c130d0",
   "metadata": {},
   "source": [
    "## Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf553ea-0e80-45e0-85e1-b3c52058ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "configuration = GPT2Config()\n",
    "configuration.use_dropmatmul = True\n",
    "configuration.use_lightsoftmax = True\n",
    "model = LightGPT2Model(configuration)\n",
    "# model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68dcaa55-c446-402f-961b-ea642b17e746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before placing the model on GPU\n",
      "MA 0.0312 MB         Max_MA 0.0312 MB         CA 2.0 MB         Max_CA 2.0 MB \n",
      "\n",
      "After placing the model on GPU:\n",
      "MA 487.5 MB         Max_MA 487.5 MB         CA 542.0 MB         Max_CA 542.0 MB \n",
      "\n",
      "Params (empirical) 487.4688 MB\n",
      "\n",
      "Params (analytical, torch) 474.7002 MB\n",
      "\n",
      "After input batch generation, before forward pass:\n",
      "MA 487.5 MB         Max_MA 487.5 MB         CA 542.0 MB         Max_CA 542.0 MB \n",
      "\n",
      "After backward:\n",
      "MA 7799.2896 MB         Max_MA 7799.2896 MB         CA 7902.0 MB         Max_CA 7902.0 MB \n",
      "\n",
      "\n",
      "Activations (analytical, torchviz) 7587.8207 MB\n",
      "Activations (empirical) 7311.7896 MB\n"
     ]
    }
   ],
   "source": [
    "b = 4\n",
    "seq = configuration.n_positions\n",
    "x = torch.randint(0, configuration.vocab_size, size=(b,seq), device='cuda')\n",
    "estimate_layer_memory(copy.deepcopy(model), x, device='cuda', input_shape=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "101d90c9-775a-4f89-9837-708acec95730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------+\n",
      "|                   batch_size=4, seq_length=1024, emb_size=768, blocks=12                   |\n",
      "+--------------+--------------------------+-------------------------+------------------------+\n",
      "|    Model     | Max Memory Allocated, MB | Max Memory Reserved, MB | Activations Memory, MB |\n",
      "+--------------+--------------------------+-------------------------+------------------------+\n",
      "| Vanilla gpt2 |         12119.3          |         12654.0         |        11631.8         |\n",
      "|  Light gpt2  |          7799.3          |          7902.0         |         7311.8         |\n",
      "+--------------+--------------------------+-------------------------+------------------------+\n"
     ]
    }
   ],
   "source": [
    "table = PrettyTable()\n",
    "table.field_names = [\"Model\", \"Max Memory Allocated, MB\", \"Max Memory Reserved, MB\", \"Activations Memory, MB\"]\n",
    "table.add_row([\"Vanilla gpt2\", 12119.3, 12654.0, 11631.8])\n",
    "table.add_row([\"Light gpt2\", 7799.3, 7902.0, 7311.8])\n",
    "table.title = \"batch_size=4, seq_length=1024, emb_size=768, blocks=12\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c813b-ebbd-4197-aa91-58c48e9f4340",
   "metadata": {},
   "source": [
    "# Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da2dbeb1-507a-400e-a6b5-516084755fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "b = 2\n",
    "seq = 1024\n",
    "x1 = torch.randint(0, 50257, size=(b,seq), device='cuda')\n",
    "configuration = GPT2Config(n_layer=1)\n",
    "model1 = GPT2Model(configuration)\n",
    "model1 = model1.cuda()\n",
    "y1 = model1(x1).last_hidden_state\n",
    "y1.cos().mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c301c1a-3168-4237-8e2b-bc41b8dc3aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "b = 2\n",
    "seq = 1024\n",
    "x2 = torch.randint(0, 50257, size=(b,seq), device='cuda')\n",
    "configuration = GPT2Config(n_layer=1)\n",
    "configuration.use_dropmatmul = True\n",
    "configuration.use_lightsoftmax = True\n",
    "model2 = LightGPT2Model(configuration)\n",
    "model2 = model2.cuda()\n",
    "y2 = model2(x2).last_hidden_state\n",
    "y2.cos().mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccf6cb7b-82e2-464a-b185-43400061d0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True, True, True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(x1, x2), \\\n",
    "torch.allclose(model1.h[0].attn.c_attn.weight, model2.h[0].attn.c_attn.weight), \\\n",
    "torch.allclose(y1, y2), \\\n",
    "torch.allclose(model1.h[0].attn.c_attn.weight.grad, model2.h[0].attn.c_attn.weight.grad), \\\n",
    "torch.allclose(model1.h[0].mlp.c_fc.weight.grad, model2.h[0].mlp.c_fc.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e69f5a-25ed-4275-acb5-428ad9e77dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mark19",
   "language": "python",
   "name": "mark19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
