{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a9a9d95-d177-4414-9097-4faf97666a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53e4e6e1-1385-42ac-a070-e2827e4c32e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct 26 21:16:34 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:1C:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    40W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee9efd87-b338-4779-9e32-f0c26f8a0ddb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Config, GPT2Tokenizer, GPT2LMHeadModel, GPT2Model\n",
    "import transformers\n",
    "import torch\n",
    "from torch import nn\n",
    "import copy\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "from light_attention.models.gpt2 import LightGPT2LMHeadModel, LightGPT2Model, LightGPT2Attention\n",
    "from light_attention.profile import estimate_layer_memory, mem_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c161eee-1a9c-4782-9dff-da4d1a92caf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.11.0+cu102', '4.23.1', device(type='cuda'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__, transformers.__version__, torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3803db79-bbf3-4c85-9cc6-31302f971f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 15835"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d4c235-73ff-4cd5-b142-e2d0eeeb223b",
   "metadata": {},
   "source": [
    "# HuggingFace GPT2Model vs LightGPT2Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53d4e32-683a-4724-8b54-30cdf8b11717",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bdadb0-189c-40ca-a14b-1a696d025feb",
   "metadata": {},
   "source": [
    "### GPT2-small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b147fbcc-ff78-418e-b591-d82528aa740f",
   "metadata": {},
   "source": [
    "### Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7219ec92-4e2d-4f28-b916-22d276b5e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "configuration = GPT2Config(n_head=12, n_layer=12, n_positions=1024, n_embd=768)\n",
    "model = GPT2Model(configuration)\n",
    "b = 4\n",
    "seq = configuration.n_positions\n",
    "emb = configuration.n_embd\n",
    "x = torch.randint(0, configuration.vocab_size, size=(b,seq), device='cuda')\n",
    "estimate_layer_memory(copy.deepcopy(model), x, device='cuda', input_shape=None)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb9686f-dfeb-4aac-8ffe-6809b9c130d0",
   "metadata": {},
   "source": [
    "### Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf553ea-0e80-45e0-85e1-b3c52058ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "configuration = GPT2Config(n_head=12, n_layer=12, n_positions=1024, n_embd=768)\n",
    "configuration.use_dropmatmul = True\n",
    "configuration.use_lightsoftmax = True\n",
    "model = LightGPT2Model(configuration)\n",
    "b = 4\n",
    "seq = configuration.n_positions\n",
    "x = torch.randint(0, configuration.vocab_size, size=(b,seq), device='cuda')\n",
    "estimate_layer_memory(copy.deepcopy(model), x, device='cuda', input_shape=None)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4025a64d-388d-441a-98a0-1b897789d723",
   "metadata": {},
   "source": [
    "### GPT2-medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95361a-70d3-494a-aa14-a44d971bb211",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "configuration = GPT2Config(n_head=16, n_layer=24, n_positions=1024, n_embd=1024)\n",
    "model = GPT2Model(configuration)\n",
    "b = 4\n",
    "seq = configuration.n_positions\n",
    "x = torch.randint(0, configuration.vocab_size, size=(b,seq), device='cuda')\n",
    "estimate_layer_memory(copy.deepcopy(model), x, device='cuda', input_shape=None)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651c24e-b4cb-4f2c-9ff8-ee43bcaa3ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "configuration = GPT2Config(n_head=16, n_layer=24, n_positions=1024, n_embd=1024)\n",
    "configuration.use_dropmatmul = True\n",
    "configuration.use_lightsoftmax = True\n",
    "model = LightGPT2Model(configuration)\n",
    "b = 4\n",
    "seq = configuration.n_positions\n",
    "x = torch.randint(0, configuration.vocab_size, size=(b,seq), device='cuda')\n",
    "estimate_layer_memory(copy.deepcopy(model), x, device='cuda', input_shape=None)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b0d554-5610-4402-ac07-359c9243d767",
   "metadata": {},
   "source": [
    "### GPT2-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a7b630-2b42-424d-82c4-f688c8aa71e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "configuration = GPT2Config(n_head=20, n_layer=36, n_positions=1024, n_embd=1280)\n",
    "model = GPT2Model(configuration)\n",
    "b = 4\n",
    "seq = configuration.n_positions\n",
    "x = torch.randint(0, configuration.vocab_size, size=(b,seq), device='cuda')\n",
    "estimate_layer_memory(copy.deepcopy(model), x, device='cuda', input_shape=None)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f142ba07-28ae-4834-9ac8-55a2933d70a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "configuration = GPT2Config(n_head=20, n_layer=36, n_positions=1024, n_embd=1280)\n",
    "configuration.use_dropmatmul = True\n",
    "configuration.use_lightsoftmax = True\n",
    "model = LightGPT2Model(configuration)\n",
    "b = 4\n",
    "seq = configuration.n_positions\n",
    "x = torch.randint(0, configuration.vocab_size, size=(b,seq), device='cuda')\n",
    "estimate_layer_memory(copy.deepcopy(model), x, device='cuda', input_shape=None)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bdf238-22bd-48f6-9011-70b51d1120f1",
   "metadata": {},
   "source": [
    "## GPT2-xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520d3f18-dc2d-4ede-88df-14ea023d16b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "configuration = GPT2Config(n_head=25, n_layer=48, n_positions=1024, n_embd=1600)\n",
    "model = GPT2Model(configuration)\n",
    "b = 2\n",
    "seq = configuration.n_positions\n",
    "x = torch.randint(0, configuration.vocab_size, size=(b,seq), device='cuda')\n",
    "estimate_layer_memory(copy.deepcopy(model), x, device='cuda', input_shape=None)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95606bd5-c4fc-4566-bd72-6fd7a388ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "configuration = GPT2Config(n_head=25, n_layer=48, n_positions=1024, n_embd=1600)\n",
    "configuration.use_dropmatmul = True\n",
    "configuration.use_lightsoftmax = True\n",
    "model = LightGPT2Model(configuration)\n",
    "b = 4\n",
    "seq = configuration.n_positions\n",
    "x = torch.randint(0, configuration.vocab_size, size=(b,seq), device='cuda')\n",
    "estimate_layer_memory(copy.deepcopy(model), x, device='cuda', input_shape=None)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c813b-ebbd-4197-aa91-58c48e9f4340",
   "metadata": {},
   "source": [
    "# Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1222204f-a625-428a-84ec-758046879998",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743a8918-787b-45a5-a0ce-4d0fac1ffcf8",
   "metadata": {},
   "source": [
    "## FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da2dbeb1-507a-400e-a6b5-516084755fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "b = 4\n",
    "seq = 1024\n",
    "x1 = torch.randint(0, 50257, size=(b,seq), device='cuda')\n",
    "configuration = GPT2Config(n_layer=1)\n",
    "model1 = GPT2Model(configuration).to(device)\n",
    "# model1.eval()\n",
    "y1 = model1(x1).last_hidden_state\n",
    "y1.cos().mean().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75774e85-0b49-4422-ab1b-2052da580e94",
   "metadata": {},
   "source": [
    "#### LightGPT2Model through model class..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c301c1a-3168-4237-8e2b-bc41b8dc3aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "b = 4\n",
    "seq = 1024\n",
    "x2 = torch.randint(0, 50257, size=(b,seq), device='cuda')\n",
    "configuration = GPT2Config(n_layer=1)\n",
    "configuration.use_dropmatmul = True\n",
    "configuration.use_lightsoftmax = True\n",
    "model2 = LightGPT2Model(configuration).to(device)\n",
    "# model2.eval()\n",
    "y2 = model2(x2).last_hidden_state\n",
    "y2.cos().mean().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b78c31-efdb-4e93-b4b7-c0e538182498",
   "metadata": {},
   "source": [
    "#### ... or through attention module substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fbbc963-2ff6-4a62-9cba-9d5ef5d5d646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "b = 4\n",
    "seq = 1024\n",
    "x2 = torch.randint(0, 50257, size=(b,seq), device='cuda')\n",
    "configuration = GPT2Config(n_layer=1)\n",
    "configuration.use_dropmatmul = True\n",
    "configuration.use_lightsoftmax = True\n",
    "model2 = GPT2Model(configuration)\n",
    "for i in range(len(model2.h)):\n",
    "    weight_attn = model1.h[i].attn.c_attn.weight.detach()\n",
    "    bias_attn = model1.h[i].attn.c_attn.bias.detach()\n",
    "    weight_proj = model1.h[i].attn.c_proj.weight.detach()\n",
    "    bias_proj = model1.h[i].attn.c_proj.bias.detach()\n",
    "    model2.h[i].attn = LightGPT2Attention(configuration).cuda()\n",
    "    model2.h[i].attn.c_attn.weight = nn.Parameter(weight_attn, requires_grad=True)\n",
    "    model2.h[i].attn.c_attn.bias = nn.Parameter(bias_attn, requires_grad=True)\n",
    "    model2.h[i].attn.c_proj.weight = nn.Parameter(weight_proj, requires_grad=True)\n",
    "    model2.h[i].attn.c_proj.bias = nn.Parameter(bias_proj, requires_grad=True)\n",
    "model2 = model2.cuda()\n",
    "# model2.eval()\n",
    "y2 = model2(x2).last_hidden_state\n",
    "y2.cos().mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccf6cb7b-82e2-464a-b185-43400061d0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True, True, True, True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(x1, x2), \\\n",
    "torch.allclose(model1.h[0].attn.c_attn.weight, model2.h[0].attn.c_attn.weight), \\\n",
    "torch.allclose(model1.h[0].mlp.c_fc.weight, model2.h[0].mlp.c_fc.weight), \\\n",
    "torch.allclose(y1, y2), \\\n",
    "torch.allclose(model1.h[0].attn.c_attn.weight.grad, model2.h[0].attn.c_attn.weight.grad), \\\n",
    "torch.allclose(model1.h[0].mlp.c_fc.weight.grad, model2.h[0].mlp.c_fc.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8e69f5a-25ed-4275-acb5-428ad9e77dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.6000e-06,  1.1021e-06, -2.9144e-06,  ..., -6.6696e-06,\n",
       "          -1.1884e-06, -3.4231e-06],\n",
       "         [ 2.7922e-06, -3.8577e-08,  3.6139e-06,  ..., -6.0986e-06,\n",
       "           3.3991e-06,  6.3748e-06],\n",
       "         [-3.2562e-06,  6.4851e-07, -1.1973e-07,  ..., -8.6639e-06,\n",
       "           5.2016e-06, -1.7093e-06],\n",
       "         ...,\n",
       "         [-1.8265e-06,  2.2623e-06,  1.7213e-06,  ...,  4.6443e-07,\n",
       "          -7.9710e-06, -6.7724e-06],\n",
       "         [-7.3301e-07, -6.3993e-07,  1.1762e-06,  ..., -1.6340e-06,\n",
       "          -2.1716e-06,  1.2650e-05],\n",
       "         [-2.7116e-06, -6.4420e-09, -2.2616e-06,  ...,  7.5805e-06,\n",
       "           1.0454e-05,  1.2966e-05]], device='cuda:0'),\n",
       " tensor([[ 1.6000e-06,  1.1021e-06, -2.9144e-06,  ..., -6.6696e-06,\n",
       "          -1.1884e-06, -3.4231e-06],\n",
       "         [ 2.7922e-06, -3.8577e-08,  3.6139e-06,  ..., -6.0986e-06,\n",
       "           3.3991e-06,  6.3748e-06],\n",
       "         [-3.2562e-06,  6.4851e-07, -1.1973e-07,  ..., -8.6639e-06,\n",
       "           5.2016e-06, -1.7093e-06],\n",
       "         ...,\n",
       "         [-1.8265e-06,  2.2623e-06,  1.7213e-06,  ...,  4.6443e-07,\n",
       "          -7.9710e-06, -6.7724e-06],\n",
       "         [-7.3301e-07, -6.3993e-07,  1.1762e-06,  ..., -1.6340e-06,\n",
       "          -2.1716e-06,  1.2650e-05],\n",
       "         [-2.7116e-06, -6.4409e-09, -2.2616e-06,  ...,  7.5805e-06,\n",
       "           1.0454e-05,  1.2966e-05]], device='cuda:0'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.h[0].attn.c_attn.weight.grad, model2.h[0].attn.c_attn.weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ec127a-4009-4861-9aba-46504bae1bdb",
   "metadata": {},
   "source": [
    "## Mixed Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ceef71c6-9ca3-43a4-9d47-34416042ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "b = 4\n",
    "seq = 1024\n",
    "x1 = torch.randint(0, 50257, size=(b,seq), device='cuda')\n",
    "configuration = GPT2Config(n_layer=1)\n",
    "model1 = GPT2Model(configuration).to(device)\n",
    "# model1.eval()\n",
    "\n",
    "with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "    y1 = model1(x1).last_hidden_state\n",
    "    y1.cos().mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b59d828-3ee1-4bba-9d9b-110cf144e120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "b = 4\n",
    "seq = 1024\n",
    "x2 = torch.randint(0, 50257, size=(b,seq), device='cuda')\n",
    "configuration = GPT2Config(n_layer=1)\n",
    "configuration.use_dropmatmul = True\n",
    "configuration.use_lightsoftmax = True\n",
    "model2 = LightGPT2Model(configuration).to(device)\n",
    "# model2.eval()\n",
    "with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "    y2 = model2(x2).last_hidden_state\n",
    "    y2.cos().mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9359e56-27a5-44b1-a6ac-add888f7dc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True, True, True, True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(x1, x2), \\\n",
    "torch.allclose(model1.h[0].attn.c_attn.weight, model2.h[0].attn.c_attn.weight), \\\n",
    "torch.allclose(model1.h[0].mlp.c_fc.weight, model2.h[0].mlp.c_fc.weight), \\\n",
    "torch.allclose(y1, y2), \\\n",
    "torch.allclose(model1.h[0].attn.c_attn.weight.grad, model2.h[0].attn.c_attn.weight.grad, atol=1e-6), \\\n",
    "torch.allclose(model1.h[0].mlp.c_fc.weight.grad, model2.h[0].mlp.c_fc.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b353b660-e58a-4fb1-9788-542b4f80377d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.9605e-07,  3.5763e-07, -2.3842e-07,  ..., -8.5831e-06,\n",
       "          -2.6226e-06, -1.7881e-06],\n",
       "         [ 5.9605e-07, -3.5763e-07,  8.9407e-07,  ..., -7.7486e-06,\n",
       "           4.3511e-06,  6.3181e-06],\n",
       "         [ 1.1921e-07,  2.9802e-07,  2.3842e-07,  ..., -1.0729e-05,\n",
       "           6.5565e-06, -4.4107e-06],\n",
       "         ...,\n",
       "         [ 0.0000e+00, -4.7684e-07, -8.9407e-07,  ..., -1.2517e-06,\n",
       "          -7.6890e-06, -4.7684e-06],\n",
       "         [ 5.3644e-07, -2.3842e-07, -4.7684e-07,  ..., -6.5565e-06,\n",
       "          -7.7486e-07,  1.3173e-05],\n",
       "         [-1.1921e-07, -1.7881e-07,  2.9802e-07,  ...,  7.9274e-06,\n",
       "           1.1086e-05,  9.7752e-06]], device='cuda:0'),\n",
       " tensor([[ 5.9605e-07,  3.5763e-07, -2.3842e-07,  ..., -8.5831e-06,\n",
       "          -2.5630e-06, -1.7881e-06],\n",
       "         [ 4.7684e-07, -2.3842e-07,  1.0133e-06,  ..., -7.7486e-06,\n",
       "           4.2915e-06,  6.3181e-06],\n",
       "         [ 1.1921e-07,  3.5763e-07,  2.3842e-07,  ..., -1.0729e-05,\n",
       "           6.4373e-06, -4.4107e-06],\n",
       "         ...,\n",
       "         [ 0.0000e+00, -5.3644e-07, -8.9407e-07,  ..., -1.2517e-06,\n",
       "          -7.8082e-06, -4.7684e-06],\n",
       "         [ 5.9605e-07, -2.3842e-07, -5.3644e-07,  ..., -6.5565e-06,\n",
       "          -7.1526e-07,  1.3173e-05],\n",
       "         [-1.1921e-07, -1.7881e-07,  2.3842e-07,  ...,  7.9274e-06,\n",
       "           1.1086e-05,  9.7752e-06]], device='cuda:0'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.h[0].attn.c_attn.weight.grad, model2.h[0].attn.c_attn.weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799971ab-e708-4ef5-a8ee-c988ff9252dd",
   "metadata": {},
   "source": [
    "# Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c61c441-bb60-40ff-9ecb-6310134aaae5",
   "metadata": {},
   "source": [
    "## Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c33e22-fe2a-4a53-96a2-5f4bb621e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeebf72-f15b-4c72-afc3-38306bbccc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "configuration = GPT2Config(n_layer=12)\n",
    "model1 = GPT2Model(configuration).to(device)\n",
    "# model1.eval()\n",
    "seq = configuration.n_positions\n",
    "emb = configuration.n_embd\n",
    "samples = 100\n",
    "b = 8\n",
    "seq = 1024\n",
    "xs = torch.randint(0, 50257, size=(samples, b,seq), device=device)\n",
    "\n",
    "# fake run to allocate memory\n",
    "with torch.no_grad():\n",
    "    y = model1(xs[0])[0]\n",
    "# cuda operations are asynchronous\n",
    "torch.cuda.synchronize(device)\n",
    "\n",
    "time1 = time.time()\n",
    "with torch.no_grad():\n",
    "    for x in tqdm(xs): \n",
    "        y = model1(x)[0]\n",
    "        # cuda operations are asynchronous\n",
    "        torch.cuda.synchronize(device)\n",
    "time2 = time.time()\n",
    "print(f'Forward pass takes {((time2-time1) / samples):.3} seconds on average. Computed for {samples} samples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d978d1a-df26-4cb4-8765-227ea98727ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "configuration = GPT2Config(n_layer=12)\n",
    "configuration.use_dropmatmul = True\n",
    "configuration.use_lightsoftmax = True\n",
    "model2 = LightGPT2Model(configuration).to(device)\n",
    "# model2.eval()\n",
    "seq = configuration.n_positions\n",
    "emb = configuration.n_embd\n",
    "samples = 100\n",
    "b = 8\n",
    "seq = 1024\n",
    "xs = torch.randint(0, 50257, size=(samples, b,seq), device=device)\n",
    "\n",
    "# fake run to allocate memory\n",
    "with torch.no_grad():\n",
    "    y = model2(xs[0])[0]\n",
    "# cuda operations are asynchronous\n",
    "torch.cuda.synchronize(device)\n",
    "\n",
    "time1 = time.time()\n",
    "with torch.no_grad():\n",
    "    for x in tqdm(xs): \n",
    "        y = model2(x)[0]\n",
    "        # cuda operations are asynchronous\n",
    "        torch.cuda.synchronize(device)\n",
    "time2 = time.time()\n",
    "print(f'Forward pass takes {((time2-time1) / samples):.3} seconds on average. Computed for {samples} samples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f29b58b-da1d-4219-ba40-e59ce5718daf",
   "metadata": {},
   "source": [
    "## Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b97b7d-1973-441a-a9da-1dbfa6082433",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae2c4d2-4836-4546-af09-99cc866961ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "configuration = GPT2Config(n_layer=10)\n",
    "model1 = GPT2Model(configuration).to(device)\n",
    "# model1.eval()\n",
    "seq = configuration.n_positions\n",
    "emb = configuration.n_embd\n",
    "samples = 100\n",
    "b = 4\n",
    "seq = 1024\n",
    "xs = torch.randint(0, 50257, size=(samples, b,seq), device=device)\n",
    "\n",
    "# fake run to allocate memory\n",
    "y = model1(xs[0])[0]\n",
    "y.mean().backward()\n",
    "# cuda operations are asynchronous\n",
    "torch.cuda.synchronize(device)\n",
    "\n",
    "time1 = time.time()\n",
    "for x in tqdm(xs): \n",
    "    y = model1(x)[0]\n",
    "    torch.cuda.synchronize(device)\n",
    "    y.mean().backward()\n",
    "    # cuda operations are asynchronous\n",
    "    torch.cuda.synchronize(device)\n",
    "time2 = time.time()\n",
    "print(f'Forward pass takes {((time2-time1) / samples):.3} seconds on average. Computed for {samples} samples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c7eb7e-2985-492d-9687-c5f68dfd8614",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "configuration = GPT2Config(n_layer=10)\n",
    "configuration.use_dropmatmul = True\n",
    "configuration.use_lightsoftmax = False\n",
    "model2 = LightGPT2Model(configuration).to(device)\n",
    "model2.eval()\n",
    "seq = configuration.n_positions\n",
    "emb = configuration.n_embd\n",
    "samples = 100\n",
    "b = 4\n",
    "seq = 1024\n",
    "xs = torch.randint(0, 50257, size=(samples, b,seq), device=device)\n",
    "\n",
    "# fake run to allocate memory\n",
    "y = model2(xs[0])[0]\n",
    "y.mean().backward()\n",
    "# cuda operations are asynchronous\n",
    "torch.cuda.synchronize(device)\n",
    "\n",
    "time1 = time.time()\n",
    "for x in tqdm(xs): \n",
    "    y = model2(x)[0]\n",
    "    torch.cuda.synchronize(device)\n",
    "    y.mean().backward()\n",
    "    # cuda operations are asynchronous\n",
    "    torch.cuda.synchronize(device)\n",
    "time2 = time.time()\n",
    "print(f'Forward pass takes {((time2-time1) / samples):.3} seconds on average. Computed for {samples} samples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106259b1-9cdc-4b98-a2af-cae60b4cdc08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mark21",
   "language": "python",
   "name": "mark21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
